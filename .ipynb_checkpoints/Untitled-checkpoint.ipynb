{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb956a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\merav\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x21c12208b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nbimporter\n",
    "import dataset_class as StreetSign\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "from os.path import join\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1328)\n",
    "torch.random.manual_seed(1328);\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4f3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize normale\n",
    "tran = transforms.Compose([StreetSign.Rescale(256),StreetSign.RandomCrop(32),StreetSign.ToTensor()])\n",
    "#tran = None\n",
    "\n",
    "datatrain = StreetSign.StreetSignDataset('DITS-full\\DITS-full\\DITS-detection\\class\\classes.csv','DITS-full\\DITS-full\\DITS-detection\\class\\image',tran)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ddfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize normale\n",
    "datatest = StreetSign.StreetSignDataset('DITS-full\\DITS-full\\DITS-detection\\detection_test\\day\\classes.csv','DITS-full\\DITS-full\\DITS-detection\\detection_test\\day',tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3582c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelli PROVA\n",
    "#Non Regolarizzato\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MiniAlexNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, out_classes=4):\n",
    "        super(MiniAlexNet,self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Convoluzione 1\n",
    "            nn.Conv2d(input_channels, 16, 5, padding=2),           \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Convoluzione 2\n",
    "            nn.Conv2d(16, 32, 5, padding=2),                       \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Convoluzione 3\n",
    "            nn.Conv2d(32, 64, 3, padding=1),                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Convoluzione 4\n",
    "            nn.Conv2d(64, 128, 3, padding=1),                      \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Convoluzione 5\n",
    "            nn.Conv2d(128, 256, 3, padding=1),                     \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            # Fully Connected 6\n",
    "            nn.Linear(4608, 2048),                                 \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Fully Connected 7\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Fully Connected 8\n",
    "            nn.Linear(1024, out_classes)\n",
    "            \n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x.view(x.shape[0], -1))\n",
    "        return x\n",
    "    \n",
    "#Regolarizzato\n",
    "class MiniAlexNetBN(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_classes=4):\n",
    "        super(MiniAlexNetBN, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, 5, padding=2),           \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm2d(16),                                    \n",
    "            nn.Conv2d(16, 32, 5, padding=2),                       \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),                       \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),                      \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),                     \n",
    "            nn.MaxPool2d(2),                                       \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.BatchNorm1d(4608),                                  \n",
    "            nn.Linear(4608, 2048),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, output_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x.view(x.shape[0],-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d44b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzioni\n",
    "\n",
    "# train:\n",
    "from os.path import join\n",
    "import torch.optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_classifier(model, train_loader, test_loader, exp_name='segnali', lr = 0.001,\n",
    "                     epochs= 10, momentum = 0.9, logdir = 'C:/Users/user/logs'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum)\n",
    "    \n",
    "    # meters:\n",
    "    loss_meter = AverageValueMeter()\n",
    "    acc_meter = AverageValueMeter()\n",
    "    \n",
    "    writer= SummaryWriter(join(logdir, exp_name))\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # definiamo un dizionario con i loader di train e test:\n",
    "    loader = {\n",
    "        'train' : train_loader,\n",
    "        'test' : test_loader\n",
    "        }\n",
    "    # inizializzo il global step:\n",
    "    global_step = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for mode in ['train', 'test']:\n",
    "            loss_meter.reset(); acc_meter.reset()\n",
    "            \n",
    "            model.train() if mode == 'train' else model.eval()\n",
    "            \n",
    "            with torch.set_grad_enabled(mode == 'train'):\n",
    "                for i, batch in enumerate(loader[mode]):\n",
    "                    x = batch['image'].to(device)\n",
    "                    y = batch['label'].to(device)\n",
    "                    \n",
    "                    output = model(x)\n",
    "                    # aggiorniamo il global_step che conta il numero di campioni visti durante il training:\n",
    "                    n = x.shape[0]  # n elementi nel batch\n",
    "                    global_step += n\n",
    "                    l = criterion(output, y)\n",
    "                    \n",
    "                    if mode == 'train':\n",
    "                        l.backward()\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad\n",
    "                    \n",
    "                    acc = accuracy_score(y.to('cpu'), output.to('cpu').max(1)[1])\n",
    "                    loss_meter.add(l.item(), n)\n",
    "                    acc_meter.add(acc, n)\n",
    "                    \n",
    "                    # loggiamo i dati iterazione per iterazione solo durante il training:\n",
    "                    if mode == 'train':\n",
    "                        writer.add_scalar('loss/train', loss_meter.value(), global_step=global_step)\n",
    "                        writer.add_scalar('accuracy/train', acc_meter.value(), global_step=global_step)\n",
    "                        \n",
    "            # loggiamo le stime finali sia di training che di test alla fine dell'epoca\n",
    "            writer.add_scalar('loss/' + mode, loss_meter.value(), global_step=global_step)\n",
    "            writer.add_scalar('accuracy/' + mode, acc_meter.value(), global_step=global_step)\n",
    "        \n",
    "        # conserviamo i pesi del modello alla fine di un ciclo di traininge test:\n",
    "        torch.save(model.state_dict(), \"%s-%d.pth\" % (exp_name, e+1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee958a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predizioni sul test set\n",
    "def test_classifier(model, loader):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    predictions, labels = [], []\n",
    "    for batch in loader:\n",
    "        x = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        preds = output.to(\"cpu\").max(1)[1].numpy()\n",
    "        labs = y.to(\"cpu\").numpy()\n",
    "        \n",
    "        predictions.extend(list(preds))\n",
    "        labels.extend(list(labs))\n",
    "        \n",
    "    return np.array(predictions), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6866232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valutazione Modello:\n",
    "\n",
    "# Average Value Meter: servir√† per calcolare la media delle loss pesata sulle dim dei batch\n",
    "class AverageValueMeter():\n",
    "    def __init(self):\n",
    "        super(AverageValueMeter,self).__init__()\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.num = 0\n",
    "    \n",
    "    def add(self, value, num):\n",
    "        self.sum += num * value\n",
    "        self.num += num\n",
    "    \n",
    "    def value(self):\n",
    "        try:\n",
    "            return self.sum/self.num\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28bd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REC Curve\n",
    "\n",
    "def rec_curve(predictions, gt):\n",
    "    assert predictions.shape == gt.shape\n",
    "    # calcoliamo tutti gli errori mediante MAE\n",
    "    errors = np.abs(np.array((predictions-gt)))\n",
    "    \n",
    "    # prendiamo i valori unici degli errori e ordiniamoli\n",
    "    tolerances = sorted(np.unique(errors))\n",
    "    correct= [] #lista delle \"accuracy\" relative a ogni soglia\n",
    "    \n",
    "    for t in tolerances:\n",
    "        correct.append((errors<=t).mean()) # frazione di elementi \"correttamente\" regressi\n",
    "    AUC = np.trapz(correct, tolerances) #a rea sotto la curva calcolata col metodo dei trapezi\n",
    "    tot_area = np.max(tolerances)*1 # area totale\n",
    "    AOC = tot_area - AUC\n",
    "    # restituiamo le soglie, la frazione di campioni correttamente regressi e l'area sopra la curva\n",
    "    return tolerances, correct, AOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59e1d1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (3401575101.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print tolerances\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "print (tolerances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0e9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
