{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57043deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "import python_file.dataclass as StreetSign\n",
    "import python_file.function as Function\n",
    "import python_file.network as Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f12704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniAlexNetV2(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ReLU()\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network.MiniAlexNetV2()\n",
    "model.load_state_dict(torch.load('modelli\\minialexnetv2_dataset-200.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9120d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniAlexNet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Network.MiniAlexNet()\n",
    "model1.load_state_dict(torch.load('modelli\\minialexnet_dataset-100.pth'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff9cc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNetColor(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 18, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(18, 28, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=700, out_features=360, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=360, out_features=252, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=252, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Network.LeNetColor()\n",
    "model2.load_state_dict(torch.load('modelli\\lenet_dataset-100.pth'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32b780",
   "metadata": {},
   "source": [
    "Per  testare la nostra rete possiamo usare le immagini presenti nella cartella \"DITS-full\\DITS-full\\DITS-detection\\class\\image\\\", che sono numerate da 1 a 1356. \n",
    "Oppure si può usare una qualsiasi immagine presa da internet come nell'esempio in cui si utilizzerà l'immagine \"image\\image.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb224a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=45x45>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"DITS-full\\DITS-full\\DITS-detection\\class\\image\\\\736.png\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39335eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor()])\n",
    "img_t = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e6d9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le dimensioni di input previste dal tuo modello\n",
    "input_height = 32\n",
    "input_width = 32\n",
    "\n",
    "mean = 0.6529\n",
    "std = 0.3422\n",
    "\n",
    "# Applica le trasformazioni alle dimensioni desiderate\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((input_height, input_width)),\n",
    "    transforms.ToTensor(),  # Converte l'immagine in un tensore PyTorch\n",
    "    #transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "img_t = preprocess(img)  # Ora img_tensor è un tensore PyTorch valido\n",
    "\n",
    "# Assicurati che img_tensor sia 4D (batch_size, canali, altezza, larghezza)\n",
    "img_t = img_t.unsqueeze(0)  # Aggiunge una dimensione di batch\n",
    "\n",
    "# Seleziona solo i primi 3 canali (RGB)\n",
    "img_t = img_t[:, :3, :, :]\n",
    "\n",
    "# Ora puoi passare img_tensor al modello\n",
    "output = model(img_t).detach().numpy().argmax()\n",
    "\n",
    "# Ora puoi passare img_tensor al modello\n",
    "output1 = model1(img_t).detach().numpy().argmax()\n",
    "\n",
    "# Ora puoi passare img_tensor al modello\n",
    "output2 = model2(img_t).detach().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb28c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinialexnetV2 2\n",
      "Minialexnet 1\n",
      "LeNet 2\n",
      "\n",
      "\n",
      "Il risultato della MiniAlexNetV2 è Warning\n"
     ]
    }
   ],
   "source": [
    "print(\"MinialexnetV2\",output)\n",
    "print(\"Minialexnet\",output1)\n",
    "print(\"LeNet\",output2)\n",
    "\n",
    "if (output == 0):\n",
    "    print(\"\\n\\nIl risultato della MiniAlexNetV2 è Indicatory\")\n",
    "\n",
    "elif (output == 1):\n",
    "    print(\"\\n\\nIl risultato della MiniAlexNetV2 è Prohibitory\")\n",
    "    \n",
    "elif (output == 2):\n",
    "    print(\"\\n\\nIl risultato della MiniAlexNetV2 è Warning\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR 404 NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc6817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
