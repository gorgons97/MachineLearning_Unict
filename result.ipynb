{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57043deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import Dataset as Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "import python_file.dataclass as StreetSign\n",
    "import python_file.function as Function\n",
    "import python_file.network as Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f12704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniAlexNetV2(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ReLU()\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network.MiniAlexNetV2()\n",
    "model.load_state_dict(torch.load('modelli\\minialexnetv2_dataset-100.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c859d93b",
   "metadata": {},
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "img = Image.open(\"image\\images.png\")\n",
    "transform = transforms.ToTensor()\n",
    "img_t = transform(img)\n",
    "\n",
    "print(\"Shape of img_t:\", img_t.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36a6e9fa",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Scarica l'immagine dall'URL\n",
    "url = \"https://media.istockphoto.com/id/178748186/it/foto/milano.jpg?s=612x612&w=0&k=20&c=BuIy0rfZhncc4KHOkzShMYptkVFDqYbFVEA7fN_F6h4=\"\n",
    "response = requests.get(url)\n",
    "image_bytes = BytesIO(response.content)\n",
    "\n",
    "# Apri l'immagine con PIL\n",
    "img = Image.open(image_bytes).convert('RGB')\n",
    "\n",
    "# Verifica la forma dell'immagine\n",
    "img_shape = img.size\n",
    "\n",
    "# Se l'immagine ha un formato errato (altezza, larghezza), invertilo\n",
    "if img_shape[0] > img_shape[1]:\n",
    "    img = img.transpose(Image.Transpose.ROTATE_90)\n",
    "\n",
    "# Verifica nuovamente la forma dell'immagine dopo l'inversione\n",
    "img_shape = img.size\n",
    "print(\"Shape of img:\", img_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb224a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=48x47>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"DITS-full\\DITS-full\\DITS-detection\\class\\image\\\\503.png\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39335eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor()])\n",
    "img_t = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6d9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le dimensioni di input previste dal tuo modello\n",
    "input_height = 32\n",
    "input_width = 32\n",
    "\n",
    "mean = 0.6529\n",
    "std = 0.3422\n",
    "\n",
    "# Applica le trasformazioni alle dimensioni desiderate\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((input_height, input_width)),\n",
    "    transforms.ToTensor(),  # Converte l'immagine in un tensore PyTorch\n",
    "    #transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "img_t = preprocess(img)  # Ora img_tensor è un tensore PyTorch valido\n",
    "\n",
    "# Assicurati che img_tensor sia 4D (batch_size, canali, altezza, larghezza)\n",
    "img_t = img_t.unsqueeze(0)  # Aggiunge una dimensione di batch\n",
    "\n",
    "# Seleziona solo i primi 3 canali (RGB)\n",
    "img_t = img_t[:, :3, :, :]\n",
    "\n",
    "# Ora puoi passare img_tensor al modello\n",
    "output = model(img_t).detach().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb28c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "warning\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "\n",
    "if (output == 0):\n",
    "    print(\"indicatory\")\n",
    "\n",
    "elif (output == 1):\n",
    "    print(\"prohibitory\")\n",
    "    \n",
    "elif (output == 2):\n",
    "    print(\"warning\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR 404 NOT FOUND\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "419a0351",
   "metadata": {},
   "source": [
    "pred = output\n",
    "print(\"CNN predictions: \", output)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78470f1e",
   "metadata": {},
   "source": [
    "pred_dict = pred[0]\n",
    "\n",
    "# Estrai le informazioni di interesse dal tensore\n",
    "boxes = pred[:, :4]  # Le prime 4 colonne potrebbero rappresentare i bounding box\n",
    "labels = pred[:, 4]  # La quinta colonna potrebbe rappresentare le etichette\n",
    "scores = pred[:, 5:]  # Le colonne dalla sesta in poi potrebbero rappresentare gli score\n",
    "\n",
    "# Converti i tensori PyTorch in numpy arrays\n",
    "boxes = boxes.detach().numpy()\n",
    "labels = labels.detach().numpy()\n",
    "scores = scores.detach().numpy()\n",
    "\n",
    "\n",
    "print(\"Predizione con lo score più alto: \\n bounding box:\\t \", boxes[0], \"\\n Classe:\\t\", labels[0], \"\\n score:\\t\", scores[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef990fd",
   "metadata": {},
   "source": [
    "threshold = 0.5\n",
    "idx = np.where(abs(scores) > threshold)[0]\n",
    "boxes = boxes[idx]\n",
    "labels = labels[idx]\n",
    "scores = scores[idx]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc520e49",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)\n",
    "ax = plt.gca()\n",
    "for box, label, score in zip(boxes, labels, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    if isinstance(label, (list, np.ndarray)):\n",
    "        label = label[0]  # Se label è un array, prendi il primo elemento\n",
    "\n",
    "    if isinstance(score, (list, np.ndarray)):\n",
    "        score = score[0]  # Se score è un array, prendi il primo elemento\n",
    "\n",
    "    label = int(label)  # Converti l'etichetta in un intero\n",
    "    ax.add_patch(plt.Rectangle((x1, y1), w, h, fill=False, color=\"red\"))\n",
    "    ax.text(x1, y1, \"Class {}: {:.2f}\".format(label, score), fontsize=15, color=\"white\", bbox=dict(facecolor=\"red\", alpha=0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df3fefc5",
   "metadata": {},
   "source": [
    "category_map = {\n",
    "    1: 'indication',\n",
    "    2: 'prohibitory',\n",
    "    3: 'warning'\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "358e49d2",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)\n",
    "ax = plt.gca()\n",
    "for box, label, score in zip(boxes, labels, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, fill=False, color=\"red\")\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x1, y1, f\"{category_map[label]}: {score:.2f}\", fontsize=15, color=\"white\", bbox=dict(facecolor=\"red\", alpha=0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
