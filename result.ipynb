{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57043deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import Dataset as Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "import python_file.dataclass as StreetSign\n",
    "import python_file.function as Function\n",
    "import python_file.network as Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f12704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniAlexNetV2(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ReLU()\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network.MiniAlexNetV2()\n",
    "model.load_state_dict(torch.load('modelli\\minialexnetv2_dataset-100.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c859d93b",
   "metadata": {},
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "img = Image.open(\"image\\images.png\")\n",
    "transform = transforms.ToTensor()\n",
    "img_t = transform(img)\n",
    "\n",
    "print(\"Shape of img_t:\", img_t.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36a6e9fa",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Scarica l'immagine dall'URL\n",
    "url = \"https://media.istockphoto.com/id/178748186/it/foto/milano.jpg?s=612x612&w=0&k=20&c=BuIy0rfZhncc4KHOkzShMYptkVFDqYbFVEA7fN_F6h4=\"\n",
    "response = requests.get(url)\n",
    "image_bytes = BytesIO(response.content)\n",
    "\n",
    "# Apri l'immagine con PIL\n",
    "img = Image.open(image_bytes).convert('RGB')\n",
    "\n",
    "# Verifica la forma dell'immagine\n",
    "img_shape = img.size\n",
    "\n",
    "# Se l'immagine ha un formato errato (altezza, larghezza), invertilo\n",
    "if img_shape[0] > img_shape[1]:\n",
    "    img = img.transpose(Image.Transpose.ROTATE_90)\n",
    "\n",
    "# Verifica nuovamente la forma dell'immagine dopo l'inversione\n",
    "img_shape = img.size\n",
    "print(\"Shape of img:\", img_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb224a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=58x59>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"DITS-full\\DITS-full\\DITS-detection\\class\\image\\\\100.png\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39335eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor()])\n",
    "img_t = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6d9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le dimensioni di input previste dal tuo modello\n",
    "input_height = 32\n",
    "input_width = 32\n",
    "\n",
    "mean = 0.6529\n",
    "std = 0.3422\n",
    "\n",
    "# Applica le trasformazioni alle dimensioni desiderate\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((input_height, input_width)),\n",
    "    transforms.ToTensor(),  # Converte l'immagine in un tensore PyTorch\n",
    "    #transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "img_t = preprocess(img)  # Ora img_tensor è un tensore PyTorch valido\n",
    "\n",
    "# Assicurati che img_tensor sia 4D (batch_size, canali, altezza, larghezza)\n",
    "img_t = img_t.unsqueeze(0)  # Aggiunge una dimensione di batch\n",
    "\n",
    "# Seleziona solo i primi 3 canali (RGB)\n",
    "img_t = img_t[:, :3, :, :]\n",
    "\n",
    "# Ora puoi passare img_tensor al modello\n",
    "output = model(img_t).detach().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb28c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "prohibitory\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "\n",
    "if (output == 0):\n",
    "    print(\"indicatory\")\n",
    "\n",
    "elif (output == 1):\n",
    "    print(\"prohibitory\")\n",
    "    \n",
    "elif (output == 2):\n",
    "    print(\"warning\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR 404 NOT FOUND\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "419a0351",
   "metadata": {},
   "source": [
    "pred = output\n",
    "print(\"CNN predictions: \", output)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78470f1e",
   "metadata": {},
   "source": [
    "pred_dict = pred[0]\n",
    "\n",
    "# Estrai le informazioni di interesse dal tensore\n",
    "boxes = pred[:, :4]  # Le prime 4 colonne potrebbero rappresentare i bounding box\n",
    "labels = pred[:, 4]  # La quinta colonna potrebbe rappresentare le etichette\n",
    "scores = pred[:, 5:]  # Le colonne dalla sesta in poi potrebbero rappresentare gli score\n",
    "\n",
    "# Converti i tensori PyTorch in numpy arrays\n",
    "boxes = boxes.detach().numpy()\n",
    "labels = labels.detach().numpy()\n",
    "scores = scores.detach().numpy()\n",
    "\n",
    "\n",
    "print(\"Predizione con lo score più alto: \\n bounding box:\\t \", boxes[0], \"\\n Classe:\\t\", labels[0], \"\\n score:\\t\", scores[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef990fd",
   "metadata": {},
   "source": [
    "threshold = 0.5\n",
    "idx = np.where(abs(scores) > threshold)[0]\n",
    "boxes = boxes[idx]\n",
    "labels = labels[idx]\n",
    "scores = scores[idx]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc520e49",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)\n",
    "ax = plt.gca()\n",
    "for box, label, score in zip(boxes, labels, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    if isinstance(label, (list, np.ndarray)):\n",
    "        label = label[0]  # Se label è un array, prendi il primo elemento\n",
    "\n",
    "    if isinstance(score, (list, np.ndarray)):\n",
    "        score = score[0]  # Se score è un array, prendi il primo elemento\n",
    "\n",
    "    label = int(label)  # Converti l'etichetta in un intero\n",
    "    ax.add_patch(plt.Rectangle((x1, y1), w, h, fill=False, color=\"red\"))\n",
    "    ax.text(x1, y1, \"Class {}: {:.2f}\".format(label, score), fontsize=15, color=\"white\", bbox=dict(facecolor=\"red\", alpha=0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df3fefc5",
   "metadata": {},
   "source": [
    "category_map = {\n",
    "    1: 'indication',\n",
    "    2: 'prohibitory',\n",
    "    3: 'warning'\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "358e49d2",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)\n",
    "ax = plt.gca()\n",
    "for box, label, score in zip(boxes, labels, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, fill=False, color=\"red\")\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x1, y1, f\"{category_map[label]}: {score:.2f}\", fontsize=15, color=\"white\", bbox=dict(facecolor=\"red\", alpha=0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
